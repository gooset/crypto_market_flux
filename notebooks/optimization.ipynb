{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.17.0)\n",
      "Requirement already satisfied: optuna in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.0.0)\n",
      "Requirement already satisfied: plotly in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (5.24.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: matplotlib<4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: pandas<3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: mlflow-skinny==2.17.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (2.17.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: graphene<4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (3.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (1.13.3)\n",
      "Requirement already satisfied: scipy<2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: gunicorn<24 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: Flask<4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: cloudpickle<4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (0.35.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (4.25.5)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: packaging<25 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (24.0)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (7.1.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: colorlog in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
      "Requirement already satisfied: Mako in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
      "Requirement already satisfied: google-auth~=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.35.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.1)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Flask<4->mlflow) (3.0.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (6.4.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.48b0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow optuna plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 13:52:45.020483: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-20 13:52:45.024905: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-20 13:52:45.038808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-20 13:52:45.063457: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-20 13:52:45.070209: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-20 13:52:45.088967: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-20 13:52:46.434173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>number_of_trades</th>\n",
       "      <th>volatility</th>\n",
       "      <th>log_returns</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>31915448.00</td>\n",
       "      <td>226447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>16588695.00</td>\n",
       "      <td>93597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.436802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>18382334.00</td>\n",
       "      <td>83251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.400495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>9797253.00</td>\n",
       "      <td>42828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>11666843.00</td>\n",
       "      <td>48704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.240787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>839696.80</td>\n",
       "      <td>9573</td>\n",
       "      <td>1.363364e-06</td>\n",
       "      <td>-0.080348</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>50.834724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>893477.70</td>\n",
       "      <td>10205</td>\n",
       "      <td>1.291739e-06</td>\n",
       "      <td>0.053754</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>58.083838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>640879.06</td>\n",
       "      <td>4708</td>\n",
       "      <td>1.278455e-06</td>\n",
       "      <td>-0.028610</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>54.096049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>297733.00</td>\n",
       "      <td>2425</td>\n",
       "      <td>1.044792e-06</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>56.175853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>240827.80</td>\n",
       "      <td>2143</td>\n",
       "      <td>8.409460e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>57.623477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      open_time      open      high       low     close       volume  \\\n",
       "0    2020-12-25  0.000009  0.000168  0.000009  0.000093  31915448.00   \n",
       "1    2020-12-26  0.000093  0.000100  0.000060  0.000060  16588695.00   \n",
       "2    2020-12-27  0.000060  0.000062  0.000039  0.000040  18382334.00   \n",
       "3    2020-12-28  0.000040  0.000047  0.000040  0.000041   9797253.00   \n",
       "4    2020-12-29  0.000041  0.000041  0.000029  0.000032  11666843.00   \n",
       "..          ...       ...       ...       ...       ...          ...   \n",
       "687  2022-11-12  0.000033  0.000033  0.000029  0.000030    839696.80   \n",
       "688  2022-11-13  0.000030  0.000032  0.000030  0.000032    893477.70   \n",
       "689  2022-11-14  0.000032  0.000032  0.000029  0.000031    640879.06   \n",
       "690  2022-11-15  0.000031  0.000032  0.000031  0.000031    297733.00   \n",
       "691  2022-11-16  0.000031  0.000032  0.000031  0.000031    240827.80   \n",
       "\n",
       "     number_of_trades    volatility  log_returns    SMA_20   SMA_50        RSI  \n",
       "0              226447           NaN          NaN       NaN      NaN        NaN  \n",
       "1               93597           NaN    -0.436802       NaN      NaN        NaN  \n",
       "2               83251           NaN    -0.400495       NaN      NaN        NaN  \n",
       "3               42828           NaN     0.020366       NaN      NaN        NaN  \n",
       "4               48704           NaN    -0.240787       NaN      NaN        NaN  \n",
       "..                ...           ...          ...       ...      ...        ...  \n",
       "687              9573  1.363364e-06    -0.080348  0.000030  0.00003  50.834724  \n",
       "688             10205  1.291739e-06     0.053754  0.000030  0.00003  58.083838  \n",
       "689              4708  1.278455e-06    -0.028610  0.000031  0.00003  54.096049  \n",
       "690              2425  1.044792e-06     0.012498  0.000031  0.00003  56.175853  \n",
       "691              2143  8.409460e-07     0.000000  0.000031  0.00003  57.623477  \n",
       "\n",
       "[692 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_daily = pd.read_csv('../binance_dataset_extract/df_daily.csv')\n",
    "df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df_daily[['open', 'high', 'low', 'volume', 'number_of_trades']]\n",
    "y = df_daily['close']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RF Optimization using MLflow and Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rf_objective(trial):\n",
    "    # Random Forest Hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Cross-validation to make evaluation more robust\n",
    "    mse = -cross_val_score(rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    \n",
    "    # Log to MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param('model', 'RandomForest')\n",
    "        mlflow.log_param('n_estimators', n_estimators)\n",
    "        mlflow.log_param('max_depth', max_depth)\n",
    "        mlflow.log_param('min_samples_split', min_samples_split)\n",
    "        mlflow.log_metric('mse', mse)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 13:56:51,759] A new study created in memory with name: no-name-f8e3e5a5-5cc7-4154-aa23-0964e073626f\n",
      "[I 2024-10-20 13:56:54,479] Trial 0 finished with value: 1.0255900701532487e-11 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 0 with value: 1.0255900701532487e-11.\n",
      "[I 2024-10-20 13:56:55,578] Trial 1 finished with value: 8.798034277116017e-12 and parameters: {'n_estimators': 98, 'max_depth': 7, 'min_samples_split': 2}. Best is trial 1 with value: 8.798034277116017e-12.\n",
      "[I 2024-10-20 13:56:57,072] Trial 2 finished with value: 8.878245374716752e-12 and parameters: {'n_estimators': 127, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 1 with value: 8.798034277116017e-12.\n",
      "[I 2024-10-20 13:56:58,540] Trial 3 finished with value: 9.520815106658681e-12 and parameters: {'n_estimators': 146, 'max_depth': 6, 'min_samples_split': 6}. Best is trial 1 with value: 8.798034277116017e-12.\n",
      "[I 2024-10-20 13:56:59,342] Trial 4 finished with value: 8.496370571817133e-12 and parameters: {'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 3}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:01,531] Trial 5 finished with value: 9.072547556660513e-12 and parameters: {'n_estimators': 214, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:04,224] Trial 6 finished with value: 1.0303910107920766e-11 and parameters: {'n_estimators': 262, 'max_depth': 10, 'min_samples_split': 10}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:05,050] Trial 7 finished with value: 9.706539761360601e-12 and parameters: {'n_estimators': 88, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:07,920] Trial 8 finished with value: 9.652814711154757e-12 and parameters: {'n_estimators': 273, 'max_depth': 10, 'min_samples_split': 7}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:11,273] Trial 9 finished with value: 8.965936383580653e-12 and parameters: {'n_estimators': 276, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:11,729] Trial 10 finished with value: 1.511023690712758e-11 and parameters: {'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:12,396] Trial 11 finished with value: 8.898139734595971e-12 and parameters: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:13,595] Trial 12 finished with value: 8.868527617776844e-12 and parameters: {'n_estimators': 108, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:15,588] Trial 13 finished with value: 8.999160628507776e-12 and parameters: {'n_estimators': 184, 'max_depth': 13, 'min_samples_split': 4}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:16,198] Trial 14 finished with value: 1.4952416143487563e-11 and parameters: {'n_estimators': 76, 'max_depth': 3, 'min_samples_split': 2}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:18,061] Trial 15 finished with value: 9.080725697422112e-12 and parameters: {'n_estimators': 174, 'max_depth': 8, 'min_samples_split': 4}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:19,181] Trial 16 finished with value: 8.95580751322498e-12 and parameters: {'n_estimators': 93, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:20,738] Trial 17 finished with value: 1.029841182764192e-11 and parameters: {'n_estimators': 141, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:21,374] Trial 18 finished with value: 9.83323859320425e-12 and parameters: {'n_estimators': 68, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:22,683] Trial 19 finished with value: 9.058743801890773e-12 and parameters: {'n_estimators': 115, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:24,614] Trial 20 finished with value: 9.231079162001332e-12 and parameters: {'n_estimators': 167, 'max_depth': 12, 'min_samples_split': 5}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:25,698] Trial 21 finished with value: 8.82507902633733e-12 and parameters: {'n_estimators': 104, 'max_depth': 7, 'min_samples_split': 2}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:27,006] Trial 22 finished with value: 8.908606753617229e-12 and parameters: {'n_estimators': 101, 'max_depth': 7, 'min_samples_split': 3}. Best is trial 4 with value: 8.496370571817133e-12.\n",
      "[I 2024-10-20 13:57:27,708] Trial 23 finished with value: 8.478578089017219e-12 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 2}. Best is trial 23 with value: 8.478578089017219e-12.\n",
      "[I 2024-10-20 13:57:28,446] Trial 24 finished with value: 9.240486778924109e-12 and parameters: {'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 23 with value: 8.478578089017219e-12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for Random Forest: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 2}\n",
      "Best MSE for Random Forest: 8.478578089017219e-12\n"
     ]
    }
   ],
   "source": [
    "# Study and Optimize for Random Forest\n",
    "rf_study = optuna.create_study(direction='minimize')\n",
    "rf_study.optimize(rf_objective, n_trials=25)\n",
    "\n",
    "print(f'Best trial for Random Forest: {rf_study.best_trial.params}')\n",
    "print(f'Best MSE for Random Forest: {rf_study.best_trial.value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Xgb Optimization using MLflow and Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    # XGBoost Hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Cross-validation for robust evaluation\n",
    "    mse = -cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "    # Log to MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param('model', 'XGBoost')\n",
    "        mlflow.log_param('n_estimators', n_estimators)\n",
    "        mlflow.log_param('max_depth', max_depth)\n",
    "        mlflow.log_param('learning_rate', learning_rate)\n",
    "        mlflow.log_param('subsample', subsample)\n",
    "        mlflow.log_param('colsample_bytree', colsample_bytree)\n",
    "        mlflow.log_metric('mse', mse)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 13:58:51,919] A new study created in memory with name: no-name-d94693a7-c835-4740-8353-fa9ed1fda921\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:52,231] Trial 0 finished with value: 6.225914682102266e-10 and parameters: {'n_estimators': 221, 'max_depth': 8, 'learning_rate': 0.10784542845363564, 'subsample': 0.6640595878109652, 'colsample_bytree': 0.8205171823743469}. Best is trial 0 with value: 6.225914682102266e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:52,547] Trial 1 finished with value: 6.21959803360318e-10 and parameters: {'n_estimators': 289, 'max_depth': 5, 'learning_rate': 0.07010270772382704, 'subsample': 0.9546696998823611, 'colsample_bytree': 0.7331689154798978}. Best is trial 1 with value: 6.21959803360318e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:52,823] Trial 2 finished with value: 6.221414314582505e-10 and parameters: {'n_estimators': 203, 'max_depth': 6, 'learning_rate': 0.11455888248067501, 'subsample': 0.6870060621105641, 'colsample_bytree': 0.6400884606692819}. Best is trial 1 with value: 6.21959803360318e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:53,118] Trial 3 finished with value: 6.224011613433584e-10 and parameters: {'n_estimators': 218, 'max_depth': 11, 'learning_rate': 0.05665547739837691, 'subsample': 0.6037142161646769, 'colsample_bytree': 0.7216037521692299}. Best is trial 1 with value: 6.21959803360318e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:53,362] Trial 4 finished with value: 6.21930345675177e-10 and parameters: {'n_estimators': 201, 'max_depth': 9, 'learning_rate': 0.03337280302653487, 'subsample': 0.7735486458542333, 'colsample_bytree': 0.9804128065860147}. Best is trial 4 with value: 6.21930345675177e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:53,687] Trial 5 finished with value: 6.219647061519724e-10 and parameters: {'n_estimators': 260, 'max_depth': 11, 'learning_rate': 0.11952686636404401, 'subsample': 0.8102900304788079, 'colsample_bytree': 0.7914222250607063}. Best is trial 4 with value: 6.21930345675177e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:53,973] Trial 6 finished with value: 6.220651229992979e-10 and parameters: {'n_estimators': 234, 'max_depth': 14, 'learning_rate': 0.02940665226942879, 'subsample': 0.7856648934170123, 'colsample_bytree': 0.8433492965987855}. Best is trial 4 with value: 6.21930345675177e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:54,147] Trial 7 finished with value: 6.218910103661333e-10 and parameters: {'n_estimators': 101, 'max_depth': 12, 'learning_rate': 0.0922400080353722, 'subsample': 0.9301818102884064, 'colsample_bytree': 0.7082284778756162}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:54,499] Trial 8 finished with value: 6.223582494631152e-10 and parameters: {'n_estimators': 231, 'max_depth': 7, 'learning_rate': 0.0435142097783773, 'subsample': 0.6349749495077182, 'colsample_bytree': 0.7054342315359788}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:54,735] Trial 9 finished with value: 6.220486966889123e-10 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.018721027723928113, 'subsample': 0.621325193708179, 'colsample_bytree': 0.9693778087351954}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:54,929] Trial 10 finished with value: 6.219346769646165e-10 and parameters: {'n_estimators': 78, 'max_depth': 15, 'learning_rate': 0.2791002787053571, 'subsample': 0.9998371892684935, 'colsample_bytree': 0.610182701486255}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:55,176] Trial 11 finished with value: 6.219224238206241e-10 and parameters: {'n_estimators': 126, 'max_depth': 3, 'learning_rate': 0.010238563236852261, 'subsample': 0.8635610204962904, 'colsample_bytree': 0.9999580902971199}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:55,435] Trial 12 finished with value: 6.219707594212455e-10 and parameters: {'n_estimators': 112, 'max_depth': 3, 'learning_rate': 0.010486841605818368, 'subsample': 0.8874702718015548, 'colsample_bytree': 0.8963579278224425}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:55,696] Trial 13 finished with value: 6.219315128227087e-10 and parameters: {'n_estimators': 136, 'max_depth': 12, 'learning_rate': 0.0105293628058265, 'subsample': 0.8761443356870039, 'colsample_bytree': 0.9095957125261825}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:55,892] Trial 14 finished with value: 6.220732066314415e-10 and parameters: {'n_estimators': 71, 'max_depth': 3, 'learning_rate': 0.20959046781275223, 'subsample': 0.8981137547546512, 'colsample_bytree': 0.7657960063006379}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:56,132] Trial 15 finished with value: 6.21904137131319e-10 and parameters: {'n_estimators': 121, 'max_depth': 13, 'learning_rate': 0.018660945935043242, 'subsample': 0.8328580329397445, 'colsample_bytree': 0.6815954555580944}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:56,309] Trial 16 finished with value: 6.221444359315791e-10 and parameters: {'n_estimators': 51, 'max_depth': 13, 'learning_rate': 0.020253543970594933, 'subsample': 0.7253226993792244, 'colsample_bytree': 0.6724402933855929}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:56,582] Trial 17 finished with value: 6.219615072870031e-10 and parameters: {'n_estimators': 160, 'max_depth': 15, 'learning_rate': 0.07868515653051315, 'subsample': 0.9425068794485594, 'colsample_bytree': 0.6705530604902625}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:56,814] Trial 18 finished with value: 6.219519659253252e-10 and parameters: {'n_estimators': 103, 'max_depth': 11, 'learning_rate': 0.019398957484811772, 'subsample': 0.8238844202369106, 'colsample_bytree': 0.7589833139975252}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:57,062] Trial 19 finished with value: 6.219990107913149e-10 and parameters: {'n_estimators': 146, 'max_depth': 13, 'learning_rate': 0.16963816024024375, 'subsample': 0.9387340272963887, 'colsample_bytree': 0.6078074737380686}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:57,263] Trial 20 finished with value: 6.220737631477927e-10 and parameters: {'n_estimators': 93, 'max_depth': 10, 'learning_rate': 0.039327762349294915, 'subsample': 0.8406167919825549, 'colsample_bytree': 0.6691478158600146}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:57,515] Trial 21 finished with value: 6.219090816334248e-10 and parameters: {'n_estimators': 125, 'max_depth': 13, 'learning_rate': 0.01590811749366193, 'subsample': 0.865471274029175, 'colsample_bytree': 0.862881675961896}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:57,740] Trial 22 finished with value: 6.219547857248974e-10 and parameters: {'n_estimators': 122, 'max_depth': 13, 'learning_rate': 0.016320573023229226, 'subsample': 0.9209317250652126, 'colsample_bytree': 0.8601831809133379}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:58,003] Trial 23 finished with value: 6.219088560820312e-10 and parameters: {'n_estimators': 150, 'max_depth': 14, 'learning_rate': 0.026296397786114797, 'subsample': 0.7597680431185275, 'colsample_bytree': 0.9173154844929314}. Best is trial 7 with value: 6.218910103661333e-10.\n",
      "/tmp/ipykernel_116/3975406330.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
      "[I 2024-10-20 13:58:58,338] Trial 24 finished with value: 6.218540333068692e-10 and parameters: {'n_estimators': 148, 'max_depth': 14, 'learning_rate': 0.0306189109656581, 'subsample': 0.73398107264847, 'colsample_bytree': 0.7000494764179145}. Best is trial 24 with value: 6.218540333068692e-10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for XGBoost: {'n_estimators': 148, 'max_depth': 14, 'learning_rate': 0.0306189109656581, 'subsample': 0.73398107264847, 'colsample_bytree': 0.7000494764179145}\n",
      "Best MSE for XGBoost: 6.218540333068692e-10\n"
     ]
    }
   ],
   "source": [
    "# Study and Optimize for XGBoost\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "xgb_study.optimize(xgb_objective, n_trials=25)\n",
    "\n",
    "print(f'Best trial for XGBoost: {xgb_study.best_trial.params}')\n",
    "print(f'Best MSE for XGBoost: {xgb_study.best_trial.value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. LSTM Optimization using MLflow and Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the features for LSTM\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create LSTM data with a specific number of timesteps (assuming 10 timesteps)\n",
    "def create_lstm_data(X, y, timesteps):\n",
    "    X_lstm, y_lstm = [], []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        X_lstm.append(X[i:(i + timesteps), :])\n",
    "        y_lstm.append(y.iloc[i + timesteps])\n",
    "    return np.array(X_lstm), np.array(y_lstm)\n",
    "\n",
    "# Prepare the data with timesteps\n",
    "timesteps = 10  # You can adjust the number of timesteps based on your needs\n",
    "X_lstm, y_lstm = create_lstm_data(X_scaled, y, timesteps)\n",
    "\n",
    "# Train-test split\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_lstm = np.reshape(X_train_lstm, (X_train_lstm.shape[0], X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
    "X_test_lstm = np.reshape(X_test_lstm, (X_test_lstm.shape[0], X_test_lstm.shape[1], X_test_lstm.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# LSTM Objective function for Optuna optimization\n",
    "def lstm_objective(trial):\n",
    "    # LSTM hyperparameters\n",
    "    units = trial.suggest_int('units', 16, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=False, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Early stopping to avoid overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train_lstm, y_train_lstm,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred_lstm = model.predict(X_test_lstm)\n",
    "    mse = mean_squared_error(y_test_lstm, y_pred_lstm)\n",
    "\n",
    "    # Log to MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param('model', 'LSTM')\n",
    "        mlflow.log_param('units', units)\n",
    "        mlflow.log_param('dropout_rate', dropout_rate)\n",
    "        mlflow.log_param('learning_rate', learning_rate)\n",
    "        mlflow.log_param('batch_size', batch_size)\n",
    "        mlflow.log_param('epochs', epochs)\n",
    "        mlflow.log_metric('mse', mse)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:04:42,231] A new study created in memory with name: no-name-c24b02c7-16df-4e4e-ab01-ceea3d88ac47\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:04:48,363] Trial 0 finished with value: 3.1834030571964327e-06 and parameters: {'units': 101, 'dropout_rate': 0.2699206915918013, 'learning_rate': 0.0017055946346090866, 'batch_size': 20, 'epochs': 49}. Best is trial 0 with value: 3.1834030571964327e-06.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:04:53,930] Trial 1 finished with value: 8.439575467740129e-07 and parameters: {'units': 79, 'dropout_rate': 0.15691874677299286, 'learning_rate': 0.0024567931695510126, 'batch_size': 52, 'epochs': 36}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:04:57,916] Trial 2 finished with value: 1.6648073309747562e-05 and parameters: {'units': 93, 'dropout_rate': 0.26479883134616056, 'learning_rate': 0.00017144410261461365, 'batch_size': 20, 'epochs': 30}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:04,856] Trial 3 finished with value: 5.021965540387139e-06 and parameters: {'units': 90, 'dropout_rate': 0.2268496268217252, 'learning_rate': 0.0003333387453637971, 'batch_size': 51, 'epochs': 26}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:10,421] Trial 4 finished with value: 2.3556001442640346e-06 and parameters: {'units': 119, 'dropout_rate': 0.1700052379567335, 'learning_rate': 0.00030358668304984884, 'batch_size': 21, 'epochs': 26}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:15,369] Trial 5 finished with value: 1.5613527697390704e-06 and parameters: {'units': 95, 'dropout_rate': 0.1183227974935059, 'learning_rate': 0.0074769293143796215, 'batch_size': 29, 'epochs': 13}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:22,929] Trial 6 finished with value: 7.345612759836362e-06 and parameters: {'units': 30, 'dropout_rate': 0.37387141782273436, 'learning_rate': 0.00016941605902269676, 'batch_size': 43, 'epochs': 42}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:27,884] Trial 7 finished with value: 1.0856538463524868e-05 and parameters: {'units': 55, 'dropout_rate': 0.4518228282019746, 'learning_rate': 0.0005432231293880493, 'batch_size': 33, 'epochs': 49}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:35,156] Trial 8 finished with value: 1.2384459246940777e-06 and parameters: {'units': 83, 'dropout_rate': 0.48323975699134847, 'learning_rate': 0.0009707182376236051, 'batch_size': 49, 'epochs': 49}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:41,725] Trial 9 finished with value: 1.0644261170382165e-05 and parameters: {'units': 34, 'dropout_rate': 0.2791905427275154, 'learning_rate': 0.00025944617605144034, 'batch_size': 48, 'epochs': 41}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:46,053] Trial 10 finished with value: 3.074014189041056e-06 and parameters: {'units': 63, 'dropout_rate': 0.101520363374106, 'learning_rate': 0.003608964339717952, 'batch_size': 62, 'epochs': 13}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:51,807] Trial 11 finished with value: 8.704801939486808e-07 and parameters: {'units': 74, 'dropout_rate': 0.4983848333463462, 'learning_rate': 0.0013076283553224923, 'batch_size': 58, 'epochs': 38}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:54,773] Trial 12 finished with value: 1.9379007986327188e-05 and parameters: {'units': 50, 'dropout_rate': 0.37402662596947356, 'learning_rate': 0.002001774964514427, 'batch_size': 63, 'epochs': 37}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:05:59,802] Trial 13 finished with value: 1.4062737670304538e-06 and parameters: {'units': 70, 'dropout_rate': 0.3527455264064102, 'learning_rate': 0.003475084005305322, 'batch_size': 55, 'epochs': 33}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:06:05,956] Trial 14 finished with value: 1.0619819147484224e-06 and parameters: {'units': 113, 'dropout_rate': 0.19369716884043725, 'learning_rate': 0.0008465421577292629, 'batch_size': 58, 'epochs': 20}. Best is trial 1 with value: 8.439575467740129e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:06:12,802] Trial 15 finished with value: 4.956849374239218e-07 and parameters: {'units': 77, 'dropout_rate': 0.42617967421662456, 'learning_rate': 0.00977757991089344, 'batch_size': 39, 'epochs': 39}. Best is trial 15 with value: 4.956849374239218e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:06:18,946] Trial 16 finished with value: 3.16233313821205e-06 and parameters: {'units': 41, 'dropout_rate': 0.423680086813072, 'learning_rate': 0.00834380633856519, 'batch_size': 38, 'epochs': 43}. Best is trial 15 with value: 4.956849374239218e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:06:24,358] Trial 17 finished with value: 9.568165418156936e-07 and parameters: {'units': 78, 'dropout_rate': 0.3276419943923146, 'learning_rate': 0.004369245570832141, 'batch_size': 43, 'epochs': 34}. Best is trial 15 with value: 4.956849374239218e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:06:30,688] Trial 18 finished with value: 1.047777562990708e-06 and parameters: {'units': 18, 'dropout_rate': 0.4313966487051731, 'learning_rate': 0.005462693155247491, 'batch_size': 36, 'epochs': 28}. Best is trial 15 with value: 4.956849374239218e-07.\n",
      "/tmp/ipykernel_116/3320099725.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 14:06:37,161] Trial 19 finished with value: 4.363882677073568e-07 and parameters: {'units': 105, 'dropout_rate': 0.1612360575332044, 'learning_rate': 0.0026064487029012493, 'batch_size': 28, 'epochs': 20}. Best is trial 19 with value: 4.363882677073568e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for LSTM: {'units': 105, 'dropout_rate': 0.1612360575332044, 'learning_rate': 0.0026064487029012493, 'batch_size': 28, 'epochs': 20}\n",
      "Best MSE for LSTM: 4.363882677073568e-07\n"
     ]
    }
   ],
   "source": [
    "# Study and Optimize for LSTM\n",
    "lstm_study = optuna.create_study(direction='minimize')\n",
    "lstm_study.optimize(lstm_objective, n_trials=20)\n",
    "\n",
    "print(f'Best trial for LSTM: {lstm_study.best_trial.params}')\n",
    "print(f'Best MSE for LSTM: {lstm_study.best_trial.value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-default:Python",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
